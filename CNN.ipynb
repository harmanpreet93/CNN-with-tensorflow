{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# read mnist dataset\n",
    "mnist = input_data.read_data_sets('data', one_hot=True, validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learningRate = 0.001\n",
    "batchSize = 128\n",
    "displayStep = 20\n",
    "numIters = 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf placeholders & variables\n",
    "X = tf.placeholder(tf.float32,[None,28,28,1], name='X')\n",
    "Y_ = tf.placeholder(tf.float32,[None,10], name='labels')\n",
    "pKeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# weight Variables\n",
    "W1 = tf.Variable(tf.random_normal([7,7,1,6],stddev=0.1),name=\"W1\") # stride=1, 28*28, padding=SAME, followed by max pool\n",
    "W2 = tf.Variable(tf.random_normal([5,5,6,12],stddev=0.1),name=\"W2\") # stride=1, 14*14, padding=SAME, followed by max pool \n",
    "W3 = tf.Variable(tf.random_normal([7*7*12,128],stddev=0.1),name=\"W3\") # stride=1, 7*7, padding=SAME\n",
    "W4 = tf.Variable(tf.random_normal([128,10],stddev=0.1), name=\"W4\")\n",
    "\n",
    "# biases\n",
    "b1 = tf.Variable(tf.constant(0.1,tf.float32,[6]),name=\"b1\")\n",
    "b2 = tf.Variable(tf.constant(0.1,tf.float32,[12]),name=\"b2\")\n",
    "b3 = tf.Variable(tf.constant(0.1,tf.float32,[128]),name=\"b3\")\n",
    "b4 = tf.Variable(tf.constant(0.1,tf.float32,[10]),name=\"b4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "Y1conv = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding='SAME')\n",
    "Y1 = tf.nn.relu(Y1conv + b1)\n",
    "\n",
    "Y2 = tf.nn.max_pool(Y1,[1,2,2,1],[1,2,2,1],padding='SAME')\n",
    "\n",
    "Y3conv = tf.nn.conv2d(Y2, W2, strides=[1,1,1,1], padding='SAME')\n",
    "Y3 = tf.nn.relu(Y3conv + b2)\n",
    "\n",
    "Y3 = tf.nn.max_pool(Y3,[1,2,2,1],[1,2,2,1],'SAME')\n",
    "\n",
    "YY = tf.reshape(Y3,[-1,7*7*12])\n",
    "Y4 = tf.nn.relu(tf.matmul(YY, W3) + b3)\n",
    "\n",
    "Ylogits = tf.matmul(Y4, W4) + b4\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=Ylogits))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningRate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(Y_,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0: accuracy:0.0546875 loss: 2.39066\n",
      "Train: 20: accuracy:0.664063 loss: 1.47133\n",
      "Train: 40: accuracy:0.851563 loss: 0.554998\n",
      "Train: 60: accuracy:0.898438 loss: 0.324867\n",
      "Train: 80: accuracy:0.914063 loss: 0.245463\n",
      "Train: 100: accuracy:0.890625 loss: 0.290564\n",
      "Train: 120: accuracy:0.945313 loss: 0.17926\n",
      "Train: 140: accuracy:0.953125 loss: 0.133514\n",
      "Train: 160: accuracy:0.953125 loss: 0.155203\n",
      "Train: 180: accuracy:0.960938 loss: 0.107094\n",
      "Train: 200: accuracy:0.953125 loss: 0.146135\n",
      "Train: 220: accuracy:0.914063 loss: 0.245952\n",
      "Train: 240: accuracy:0.96875 loss: 0.126019\n",
      "Train: 260: accuracy:0.953125 loss: 0.228144\n",
      "Train: 280: accuracy:0.960938 loss: 0.117108\n",
      "Train: 300: accuracy:0.953125 loss: 0.128259\n",
      "Train: 320: accuracy:0.953125 loss: 0.124853\n",
      "Train: 340: accuracy:0.984375 loss: 0.0860289\n",
      "Train: 360: accuracy:0.96875 loss: 0.0900542\n",
      "Train: 380: accuracy:0.976563 loss: 0.0670137\n",
      "Train: 400: accuracy:0.992188 loss: 0.064476\n",
      "Train: 420: accuracy:0.953125 loss: 0.141809\n",
      "Train: 440: accuracy:0.976563 loss: 0.0689692\n",
      "Train: 460: accuracy:0.96875 loss: 0.112207\n",
      "Train: 480: accuracy:0.945313 loss: 0.138351\n",
      "Train: 500: accuracy:0.976563 loss: 0.105949\n",
      "Test accuracy:0.9743 loss: 0.0844915\n"
     ]
    }
   ],
   "source": [
    "testDict = {X:np.reshape(mnist.test.images,(-1,28,28,1)), Y_:mnist.test.labels, pKeep:1.0}\n",
    "for i in range(numIters):\n",
    "    batchX, batchY = mnist.train.next_batch(batchSize)\n",
    "    trainDict = {X:np.reshape(batchX, (-1,28,28,1)), Y_:batchY, pKeep:0.8}\n",
    "    sess.run(optimizer,feed_dict=trainDict)\n",
    "    \n",
    "    if i % displayStep == 0:\n",
    "        train_acc, train_cost = sess.run([accuracy, loss], feed_dict=trainDict)\n",
    "        print(\"Train: \" + str(i) + \": accuracy:\" + str(train_acc) + \" loss: \" + str(train_cost))\n",
    "\n",
    "# moved it out of display loop because of memory issue        \n",
    "test_acc, test_cost = sess.run([accuracy, loss], feed_dict=testDict)\n",
    "print(\"Test accuracy:\" + str(test_acc) + \" loss: \" + str(test_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding CNN\n",
    "\n",
    "This project aims to understand CNNs and how the paramters impact the results.\n",
    "\n",
    "* **Initialization of weights:**  \n",
    "Initializing weights with standard deviation of 0.1 yielded better results when ran for 500 iterations. \n",
    "Train data accuracy hit over 95% in just ~200 iterations. While it struggled to reach 95% when weights were initialized with stddev = 1.0 for 500 iterations.  \n",
    "Train: 500: accuracy:0.992188 loss: 0.0615625  \n",
    "Test: 500: accuracy:0.9771 loss: 0.0689539  \n",
    "Layer arch:  \n",
    "`CONV (stride=1)` -> `RELU` -> `CONV(stride=2)` -> `RELU` -> `CONV (stride=1)` -> `RELU` -> `FULLY-CONNECTED` -> `RELU` -> `FULLY-CONNECTED` -> `SOFTMAX` -> `OUTPUT`  \n",
    "\n",
    "\n",
    "* **Playing with Stride**  \n",
    "Changing stride from 2 to 1 in second conv layer. Not much difference in results:  \n",
    "Train: 500: accuracy:0.992188 loss: 0.0277827  \n",
    "Test accuracy:0.9745 loss: 0.0767132  \n",
    "Layer arch:  \n",
    "`CONV (stride=1)` -> `RELU` -> `CONV(stride=1)` -> `RELU` -> `CONV (stride=1)` -> `RELU` -> `FULLY-CONNECTED` -> `RELU` -> `FULLY-CONNECTED` -> `SOFTMAX` -> `OUTPUT`  \n",
    "\n",
    "\n",
    "* **Adding max pooling layer**  \n",
    "Adding maxpool decreased the accuracy to approx 98.5%.  \n",
    "Train: 500: accuracy:0.984375 loss: 0.0902737  \n",
    "Test accuracy:0.9717 loss: 0.0938389  \n",
    "Layer arch:  \n",
    "`CONV (stride=1)` -> `RELU` -> `MAXPOOL` -> `CONV (stride=1)` -> `RELU` ->  `MAXPOOL` -> `FULLY-CONNECTED` -> `RELU` -> `FULLY-CONNECTED` -> `SOFTMAX` -> `OUTPUT` \n",
    "\n",
    "* **Adding dropout**  \n",
    "Train: 500: accuracy:0.976563 loss: 0.105949  \n",
    "Test accuracy:0.9743 loss: 0.0844915  \n",
    "Dropout is applied while training data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
